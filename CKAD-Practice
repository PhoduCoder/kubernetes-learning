CKAD-Practice

#Imperative command to run a pod
#Create a pod
kubectl run <name-of-pod> --image=nginx:latest

#Delete a pod without waiting
kubectl delete pod <pod-name> --force

#create pod and also expose a port
kubectl run <my-pod-name> --image=nginx --port 80 

#Create busybox pod with a command "echo hello world"
kubectl run mypod --image=busybox --command -- /bin/sh -c "echo hello world"

#Describe pods with various verbosity 
kubectl get pod mypod -v=7
# Helps you get other details of what's happening behind the scenes.
kubectl get pod mypod -v=8
kubectl get pod mypod -v=9

#Creation of pods with a given set of labels
kubectl run mypod --image=nginx -labels="env=test,app=myapp"

#To query the pods with the labels
#For a single label, -l works
kubectl get pods -l "app=myapp"
The above command lists the pod, but when i specify both the labels
in the -l option, then it fails.

#For the above scenario, use --selector
kubectl get pods --selector "app=myapp,env=prod"

#Creation of multipod containers
#Create three busybox with various commands executed in each of them

#This will have to be created using a manifest
# We create the initial manifest using the --dry-run 
# and -o yaml option in our first command
# direct the output to a file and then
# edit the file contents to have more containers
# in it. 

#Keep in mind that --dry-run option has to be specified
# before the command option'

kubectl run multicont --dry-run -o yaml --command -- /bin/sh -c "ls; sleep 3600" > multi.yaml

Then add two more containers in the manifest

#If we wanted to check the utilization for the containers
kubectl top pods <pod-name> --containers

#Create a Pod with main container busybox and which executes
# this “while true; do echo ‘Hi I am from Main container’
# >> /var/log/index.html; sleep 5; done” and with sidecar 
#container with nginx image which exposes on port 80. 
#Use emptyDir Volume and mount this volume on path /var/log for
# busybox and on path /usr/share/nginx/html for nginx container.
# Verify both containers are running.

STEPS :
a) Create the pod template using the --dry-run command 
b) Add the other container alongwith the volume
c) Remember volume is to be added with the pod specs 
while volumeMount is to be added at containerspec

======

Remember that the shortcut to create a pod was 
kubectl run 
The only mandatory argument required is --image
However, you can supply a lot of other arguments such as 
--port , --command.
Also very handy is the --dry-run=client -o=yaml option that gives us
an ability to save the object into a YAML manifest 
without creating one

=======

Now let's move to Deployments 

The imperative command to create a deployment is 
kubectl create deploy <name-of-deploy> --image=nginx '

As like with pods, you can save the manifest in a YAML file
without creating the objects using the --dry-run=client
and -o=yaml and storing it into a YAML file

====

Note that if you were to create a busybox deployment and trying to 
execute some command, there is a slight change from pod, in that
you don't have to specify the --command explicitly, rather you just pass
a -- followed by command that you want to run. 

As an example, 
kubectl create deploy testdeploy --image=busybox --dryrun=client -o=yaml -- 
/bin/sh -c "echo Hello World!; sleep 3600;" >> my-test-deploy.yaml 

====

You can label the deployments similarly as to how 
you would label the pods or for that matter any other API resource

kubectl label deploy <name-of-deploy> {env=test,bu=bu1}

You can look for deploy with particular labels using the -l flag
As an example,
kubectl get deploy -l costcenter=3606,env=test,bu=dept1

Annotations Syntax wise work the same, but there isn't a matching selector 
that you can use to group Annotations wise, i.e. -l option 
will only apply for labels and not Annotations

====

If you want to scale a deployment, two ways to approach this
First is to add the replicas count in your manifest 
The second option is to use the imperative command of kubectl scale deploy

As an example, you will use something like below to scale the replica count to 4 for an nginx deployment

kubectl scale deploy <name-of-deploy> --replicas=4

====
Editing the image of a pod,deploy,daemonset, statefulset,cronjob imperatively

 kubectl set image (-f FILENAME | TYPE NAME) CONTAINER_NAME_1=CONTAINER_IMAGE_1 ... CONTAINER_NAME_N=CONTAINER_IMAGE_N
[options]

kubectl set image deploy/webserver nginx=busybox 

===

Kubectl rollout commands are useful to manage the rollouts of 
deployments
daemonsets
statefulsets

kubectl rollout status deploy/abc
get the status of rollout of deployments, daemonsets
and statefulsets

# Rollback to the previous deployment
  kubectl rollout undo deployment/abc

  kubectl rollout history deploy/abc
====
To autoscale 
kubectl autoscale deploy <name> --cpu-percent=40 --min=1 --max=10
===
Creating Jobs 

kubectl create job <name-of-job> --image=node --dry-run=client 
-o=yaml -- node -v >> job-manifest-sample.yaml

====
Creating cronjobs 

You only have to add a schedule in the cron format 

kubectl create cronjob my-job --image=busybox --schedule="*/1 * * * *" -- date

====

kubectl create job recurjob --image=busybox --dry-run=client -o=yaml -- date >> test-job.yam
l

Define parallelism to configure number of jobs in parallel
Define completions as say 'n' if you want to run n jobs one after the 
other in succession

====

Persistence 

PV is what to storage as Node is to compute
PVC is what ties a request for a storage to a PV
In your pod/deployment manifest, you should
specify PVC in the volume TYPE

The retain policy for PV can be 
either reclaim or delete. 

For dynamically provisioned PersistentVolumes, the default reclaim policy is "Delete"

To change from delete to reclaim , use
=====
kubectl patch pv <your-pv-name> -p '{"spec":{"persistentVolumeReclaimPolicy":"Retain"}}'

=====

For reclaim, the PV is not deleted
nor the underlying storage asset.
The PV is although considered released
But this PV is not available for another reclaim

For delete, the PV alongwith the storage asset is
deleted. 
Volumes that were dynamically provisioned inherit 
the reclaim policy of their StorageClass, 
which defaults to Delete

Say when a pod is using a PVC 
and someone manually deletes the PVC or the PV
because of the K8s finalizers attached to these resources
these are not deleted or terminated immediately.

Once the pod with the PVC claim is deleted is 
when these PV and PVCs will be deleted. 

You can reserve a PV for a given PVC
by specifying that PVC claimRef in its manifest

===
Understanding Access Modes

====

ConfigMaps for unconfidential information
Eg. database host 
1 MiB limit 

CM has data or binarydata fields
instead of spec 

Both data and binarydata are optional

data fields => UTF-8 strings
binarydata => base64-enccoded string 

name of cm => valid DNS subdomain

Each key must be alphanumeric or contain 
.,_,-

The keys stored in data must not overlap with the
keys in the binaryData field.

you can add an immutable field to a ConfigMap definition 
to create an immutable ConfigMap.

There are various ways to consume a cm
using as env variables in your containers
or mounting them as volumes 

one of the advantages of using cm as mounted volumes 
instead of env variables 
is that with cm mounted as volumes
they are automatically updated for the containers , when the cm is updated
whereas for env variables they require 
a restart of the pods

The kubelet checks whether the mounted ConfigMap is fresh on every periodic sync.
even with volumes mounted configmap, there is some delay
which equals 
kubelet sync period + cache propagation delay

A container using a ConfigMap as a subPath volume mount will NOT receive ConfigMap updates.

by adding immutable: true 
prevents changes to cm. 

Once a cm is marked immutable 
it is not possible 
to change the contents of  cm 
and you must delete and create a new cm. 
=====

There are two imperative ways to create configmap
One is from-literal where you can pass 
key=value pairs from command line

Other is to use --from-file 

Examples

kubectl create cm testcm1 --from-literal=key1=value1
#In this case we can only have one key 

Say if we wanted to create more than one keys using 
this literal method, one hack is to do the following 

kubectl create cm testliteral --from-literal=key1=value1 \
--dry-run=client -o=yaml >> test-cm.yaml 

Then create one more key value in this test-cm.yaml

Other and easier way is to just repeat the same thing again
kubectl create cm cm-name --from-literal=key1=value1 --from-literal=key2=value2


TIP:
If you wanted to create a file from command line
using echo but wanted to have it contain newline symbols
You should use the echo with -e as an option 

Command:
echo -e "app=MyApp\nenv=prod\nauthor=grv" | tee -a ui.properties

#To create configmap from a given file
kubectl create cm file-cm --from-file=app.properties

#To create configmap from all files within a directory
kubectl create cm dir-cm --from-file=config/

